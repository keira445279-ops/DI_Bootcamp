{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1 : Exploring JavaScript Variables and Data Types\n",
        "Instructions<br>\n",
        "- Create a JavaScript script that defines variables of different data types and logs them to the console.<br><br>\n",
        "Instructions\n",
        "\n",
        "- Create a new HTML file with a script tag.\n",
        "- Inside the script tag, declare variables of different data types (String, Number, Boolean, Undefined, Null).\n",
        "- Use console.log() to print each variable and its type to the browser console.\n",
        "- Open the HTML file in a web browser and inspect the console output."
      ],
      "metadata": {
        "id": "YQpLxMaD1qBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "aVfuNFzY1nTt",
        "outputId": "5dafe048-a8dc-49b5-ae18-7bd16f8397fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "    <title>Data Types Test</title>\n",
              "</head>\n",
              "<body>\n",
              "    <h3>Check the Browser Console (F12) to see the output!</h3>\n",
              "\n",
              "    <script>\n",
              "        // 1. String\n",
              "        let myString = \"Hello, JavaScript!\";\n",
              "\n",
              "        // 2. Number\n",
              "        let myNumber = 42;\n",
              "\n",
              "        // 3. Boolean\n",
              "        let myBoolean = true;\n",
              "\n",
              "        // 4. Undefined\n",
              "        let myUnderfined;\n",
              "\n",
              "        // 5. Null\n",
              "        let myNull = null;\n",
              "\n",
              "\n",
              "        // Printing values and types\n",
              "        console.log(\"Value:\", myString, \"| Type:\", typeof myString);\n",
              "        console.log(\"Value:\", myNumber, \"| Type:\", typeof myNumber);\n",
              "        console.log(\"Value:\", myBoolean, \"| Type:\", typeof myBoolean);\n",
              "        console.log(\"Value:\", myUnderfined, \"| Type:\", typeof myUnderfined);\n",
              "        console.log(\"Value:\", myNull, \"| Type:\", typeof myNull);\n",
              "    </script>\n",
              "</body>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "html_code = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Data Types Test</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h3>Check the Browser Console (F12) to see the output!</h3>\n",
        "\n",
        "    <script>\n",
        "        // 1. String\n",
        "        let myString = \"Hello, JavaScript!\";\n",
        "\n",
        "        // 2. Number\n",
        "        let myNumber = 42;\n",
        "\n",
        "        // 3. Boolean\n",
        "        let myBoolean = true;\n",
        "\n",
        "        // 4. Undefined\n",
        "        let myUnderfined;\n",
        "\n",
        "        // 5. Null\n",
        "        let myNull = null;\n",
        "\n",
        "\n",
        "        // Printing values and types\n",
        "        console.log(\"Value:\", myString, \"| Type:\", typeof myString);\n",
        "        console.log(\"Value:\", myNumber, \"| Type:\", typeof myNumber);\n",
        "        console.log(\"Value:\", myBoolean, \"| Type:\", typeof myBoolean);\n",
        "        console.log(\"Value:\", myUnderfined, \"| Type:\", typeof myUnderfined);\n",
        "        console.log(\"Value:\", myNull, \"| Type:\", typeof myNull);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "IPython.display.display(IPython.display.HTML(html_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 : JavaScript Page vs. HTML Page\n",
        "Instructions<br>\n",
        "Compare the behavior of a static HTML page with a JavaScript-enhanced HTML page.\n",
        "<br>\n",
        "\n",
        "Instructions\n",
        "\n",
        "- Create two HTML files – one with only HTML content and another with HTML and JavaScript.\n",
        "- In the first file, create a static page with headings, paragraphs, and a list.\n",
        "- In the second file, add JavaScript to dynamically modify one of the elements on page load (e.g., change the text of a heading).\n",
        "- Open both files in a web browser and observe the differences in behavior and content rendering.\n",
        "\n",
        "Expected Outcome\n",
        "\n",
        "The static HTML page should display content as is, whereas the JavaScript-enhanced page should show dynamically altered content, illustrating the interactivity added by JavaScript."
      ],
      "metadata": {
        "id": "7N-KPOT06kwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only HTML content\n",
        "html_code = '''\n",
        "<html>\n",
        "<head>\n",
        "  <title> Only HTML Content </title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>This is a heading</h1>\n",
        "  <p>This is a paragraph.</p>\n",
        "  <ul> This is a list:\n",
        "    <li>Item 1</li>\n",
        "    <li>Item 2</li>\n",
        "    <li>Item 3</li>\n",
        "  </ul>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "IPython.display.display(IPython.display.HTML(html_code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "tyPePVQe7N11",
        "outputId": "40d051f3-0eda-4af5-9fa0-65f7fb2fae08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<html>\n",
              "<head>\n",
              "  <title> Only HTML Content </title>\n",
              "</head>\n",
              "<body>\n",
              "  <h1>This is a heading</h1>\n",
              "  <p>This is a paragraph.</p>\n",
              "  <ul> This is a list:\n",
              "    <li>Item 1</li>\n",
              "    <li>Item 2</li>\n",
              "    <li>Item 3</li>\n",
              "  </ul>\n",
              "</body>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"html_only.html\", \"w\") as f:\n",
        "    f.write(html_code)"
      ],
      "metadata": {
        "id": "FO6oo_OjBMSK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML and JavaScript content\n",
        "html_js_code = '''\n",
        "<html>\n",
        "<head>\n",
        "  <title> HTML and JavaScript Content </title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>This is a heading</h1>\n",
        "  <p>This is a paragraph.</p>\n",
        "  <ul> This is a list:\n",
        "    <li>Item 1</li>\n",
        "    <li>Item 2</li>\n",
        "    <li>Item 3</li>\n",
        "  </ul>\n",
        "\n",
        "<script>\n",
        "  window.onload = function() {\n",
        "  let heading = document.querySelector('h1');\n",
        "  heading.textContent = 'New Heading';\n",
        "  heading.style.color = 'green';\n",
        "  console.log('The heading is changed successfully');\n",
        "  };\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "IPython.display.display(IPython.display.HTML(html_js_code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "r3vKeDGz8S-7",
        "outputId": "5990f9ee-b597-4561-cf97-4b96d1904f36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<html>\n",
              "<head>\n",
              "  <title> HTML and JavaScript Content </title>\n",
              "</head>\n",
              "<body>\n",
              "  <h1>This is a heading</h1>\n",
              "  <p>This is a paragraph.</p>\n",
              "  <ul> This is a list:\n",
              "    <li>Item 1</li>\n",
              "    <li>Item 2</li>\n",
              "    <li>Item 3</li>\n",
              "  </ul>\n",
              "\n",
              "<script>\n",
              "  window.onload = function() {\n",
              "  let heading = document.querySelector('h1');\n",
              "  heading.textContent = 'New Heading';\n",
              "  heading.style.color = 'green';\n",
              "  console.log('The heading is changed successfully');\n",
              "  };\n",
              "</script>\n",
              "</body>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"html_and_jjs.html\", \"w\") as f:\n",
        "    f.write(html_js_code)"
      ],
      "metadata": {
        "id": "p_jFw51OAufv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3 : Scrape Dynamic Content from Rotten Tomatoes\n",
        "Task:<br>\n",
        "- Use Selenium to navigate to the Rotten Tomatoes Certified Fresh Movies page.\n",
        "- Extract the HTML content after it’s fully loaded.\n",
        "- Use BeautifulSoup to parse and extract the movie titles, scores, and release dates.<br>\n",
        "\n",
        "Instructions\n",
        "\n",
        "- Set up Selenium WebDriver and navigate to the Rotten Tomatoes page.\n",
        "- Extract the HTML content using driver.page_source.\n",
        "- Parse the HTML with BeautifulSoup.\n",
        "- Find and extract the desired movie information.\n",
        "- Print the extracted data."
      ],
      "metadata": {
        "id": "SU7fcQ2DBXLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "!apt-get -f install -y\n",
        "!pip install selenium\n",
        "!pip install bs4\n",
        "!pip install chromedriver-autoinstaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk_r7EdFC5Wd",
        "outputId": "472925ce-9a02-4ced-8cdd-d46bfe2aeefa",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r            \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Fetched 34.8 MB in 4s (9,775 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "--2025-12-29 21:31:03--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.117.91, 172.253.117.93, 172.253.117.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.117.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117840328 (112M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 112.38M   439MB/s    in 0.3s    \n",
            "\n",
            "2025-12-29 21:31:03 (439 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [117840328/117840328]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (143.0.7499.169-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libatk-bridge2.0-0 (>= 2.5.3); however:\n",
            "  Package libatk-bridge2.0-0 is not installed.\n",
            " google-chrome-stable depends on libatk1.0-0 (>= 2.11.90); however:\n",
            "  Package libatk1.0-0 is not installed.\n",
            " google-chrome-stable depends on libatspi2.0-0 (>= 2.9.90); however:\n",
            "  Package libatspi2.0-0 is not installed.\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            " google-chrome-stable depends on libxcomposite1 (>= 1:0.4.4-1); however:\n",
            "  Package libxcomposite1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Correcting dependencies... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core gsettings-desktop-schemas libatk-bridge2.0-0 libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libvulkan1 libxcomposite1 libxtst6\n",
            "  mesa-vulkan-drivers session-migration\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core gsettings-desktop-schemas libatk-bridge2.0-0 libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libvulkan1 libxcomposite1 libxtst6\n",
            "  mesa-vulkan-drivers session-migration\n",
            "0 upgraded, 11 newly installed, 0 to remove and 6 not upgraded.\n",
            "1 not fully installed or removed.\n",
            "Need to get 11.2 MB of archives.\n",
            "After this operation, 52.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Fetched 11.2 MB in 2s (6,498 kB/s)\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "(Reading database ... 117810 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../01-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "Preparing to unpack .../02-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../03-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "Preparing to unpack .../04-libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../05-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../06-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../07-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../08-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../09-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../10-mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up google-chrome-stable (143.0.7499.169-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.39.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
            "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.11.12)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
            "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.39.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.39.0 sortedcontainers-2.4.0 trio-0.32.0 trio-websocket-0.12.2 wsproto-1.3.2\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (4.15.0)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller) (25.0)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: chromedriver-autoinstaller\n",
            "Successfully installed chromedriver-autoinstaller-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pprint  # To tidy up\n",
        "import chromedriver_autoinstaller # Import the autoinstaller\n",
        "\n",
        "chromedriver_autoinstaller.install()  # Install the ChromeDriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run Chrome in headless mode\n",
        "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
        "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
        "driver = webdriver.Chrome(options=options)"
      ],
      "metadata": {
        "id": "m5Rhy_QTDNYd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.rottentomatoes.com/browse/movies_at_home/critics:certified_fresh\"\n",
        "driver.get(url)\n",
        "\n",
        "html_content = driver.page_source\n",
        "\n",
        "print(html_content[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2MYF9YKE7RD",
        "outputId": "24da46e0-0029-42f7-b43b-028a36dc7c09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html lang=\"en\" dir=\"ltr\" xmlns=\"http://www.w3.org/1999/xhtml\" prefix=\"fb: http://www.facebook.com/2008/fbml og: http://opengraphprotocol.org/schema/\"><head prefix=\"og: http://ogp.me/ns# flixstertomat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')"
      ],
      "metadata": {
        "id": "Kleu-JfyFu9_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4.element import RubyParenthesisString\n",
        "\n",
        "grid = soup.find('div', class_ = 'discovery-tiles')\n",
        "if grid:\n",
        "    movie_items = grid.find_all('a')\n",
        "else:\n",
        "    movie_items = soup.find_all('a', href=lambda x: x and '/m/' in x)\n",
        "\n",
        "all_movies = []\n",
        "\n",
        "for item in movie_items:\n",
        "  title = item.find('span', class_ = 'p--small').get_text(strip=True)\n",
        "  link = 'https://www.rottentomatoes.com' + item.get('href')\n",
        "  crit_score = item.find('rt-text', {'slot' : 'criticsScore'})\n",
        "  aud_score = item.find('rt-text', {'slot' : 'audienceScore'})\n",
        "  release_date = item.find('span', class_ = 'smaller')\n",
        "\n",
        "  all_movies.append({\n",
        "      'Title': title,\n",
        "      'Link': link,\n",
        "      'Critics Score': crit_score.get_text(strip=True) if crit_score else 'N/A',\n",
        "      'Audience Score': aud_score.get_text(strip=True) if aud_score else 'N/A',\n",
        "      'Release Date': release_date.get_text(strip=True) if release_date else 'N/A'\n",
        "  })\n",
        "\n",
        "print(all_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GpYoJ1lGgcy",
        "outputId": "ea9b3f53-0cda-4aa2-bb34-f41a99666cfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Title': 'Happyend', 'Link': 'https://www.rottentomatoes.com/m/happyend', 'Critics Score': '98%', 'Audience Score': 'N/A', 'Release Date': 'Streaming Jan 2, 2026'}, {'Title': 'One Battle After Another', 'Link': 'https://www.rottentomatoes.com/m/one_battle_after_another', 'Critics Score': '95%', 'Audience Score': '85%', 'Release Date': 'Streaming Nov 14, 2025'}, {'Title': 'Wake Up Dead Man: A Knives Out Mystery', 'Link': 'https://www.rottentomatoes.com/m/wake_up_dead_man_a_knives_out_mystery', 'Critics Score': '92%', 'Audience Score': '94%', 'Release Date': 'Streaming Dec 12, 2025'}, {'Title': 'Train Dreams', 'Link': 'https://www.rottentomatoes.com/m/train_dreams', 'Critics Score': '95%', 'Audience Score': '90%', 'Release Date': 'Streaming Nov 21, 2025'}, {'Title': 'Eternity', 'Link': 'https://www.rottentomatoes.com/m/eternity_2025', 'Critics Score': '78%', 'Audience Score': '91%', 'Release Date': 'Streaming Dec 23, 2025'}, {'Title': 'Predators', 'Link': 'https://www.rottentomatoes.com/m/predators', 'Critics Score': '99%', 'Audience Score': '39%', 'Release Date': 'Streaming Dec 8, 2025'}, {'Title': 'Bugonia', 'Link': 'https://www.rottentomatoes.com/m/bugonia', 'Critics Score': '87%', 'Audience Score': '84%', 'Release Date': 'Streaming Nov 25, 2025'}, {'Title': 'Avatar: The Way of Water', 'Link': 'https://www.rottentomatoes.com/m/avatar_the_way_of_water', 'Critics Score': '76%', 'Audience Score': '92%', 'Release Date': 'Streaming Mar 28, 2023'}, {'Title': 'The Holdovers', 'Link': 'https://www.rottentomatoes.com/m/the_holdovers', 'Critics Score': '97%', 'Audience Score': '92%', 'Release Date': 'Streaming Nov 28, 2023'}, {'Title': 'Sentimental Value', 'Link': 'https://www.rottentomatoes.com/m/sentimental_value', 'Critics Score': '97%', 'Audience Score': '94%', 'Release Date': 'Streaming Dec 23, 2025'}, {'Title': 'Jay Kelly', 'Link': 'https://www.rottentomatoes.com/m/jay_kelly', 'Critics Score': '76%', 'Audience Score': '87%', 'Release Date': 'Streaming Dec 5, 2025'}, {'Title': 'The Perfect Neighbor', 'Link': 'https://www.rottentomatoes.com/m/the_perfect_neighbor_2025', 'Critics Score': '99%', 'Audience Score': '81%', 'Release Date': 'Streaming Oct 17, 2025'}, {'Title': 'Relay', 'Link': 'https://www.rottentomatoes.com/m/relay', 'Critics Score': '82%', 'Audience Score': '89%', 'Release Date': 'Streaming Sep 16, 2025'}, {'Title': 'Sinners', 'Link': 'https://www.rottentomatoes.com/m/sinners_2025', 'Critics Score': '97%', 'Audience Score': '96%', 'Release Date': 'Streaming Jun 3, 2025'}, {'Title': 'Avatar', 'Link': 'https://www.rottentomatoes.com/m/avatar', 'Critics Score': '81%', 'Audience Score': '82%', 'Release Date': 'Streaming Feb 10, 2016'}, {'Title': 'It Was Just an Accident', 'Link': 'https://www.rottentomatoes.com/m/it_was_just_an_accident', 'Critics Score': '98%', 'Audience Score': '92%', 'Release Date': 'Streaming Dec 16, 2025'}, {'Title': 'F1 The Movie', 'Link': 'https://www.rottentomatoes.com/m/f1_the_movie', 'Critics Score': '82%', 'Audience Score': '97%', 'Release Date': 'Streaming Aug 22, 2025'}, {'Title': 'Frankenstein', 'Link': 'https://www.rottentomatoes.com/m/frankenstein_2025', 'Critics Score': '85%', 'Audience Score': '94%', 'Release Date': 'Streaming Nov 7, 2025'}, {'Title': 'Roofman', 'Link': 'https://www.rottentomatoes.com/m/roofman', 'Critics Score': '87%', 'Audience Score': '85%', 'Release Date': 'Streaming Nov 11, 2025'}, {'Title': 'Sisu: Road to Revenge', 'Link': 'https://www.rottentomatoes.com/m/sisu_road_to_revenge', 'Critics Score': '95%', 'Audience Score': '88%', 'Release Date': 'Streaming Dec 16, 2025'}, {'Title': 'Die My Love', 'Link': 'https://www.rottentomatoes.com/m/die_my_love_2025', 'Critics Score': '74%', 'Audience Score': '46%', 'Release Date': 'Streaming Dec 9, 2025'}, {'Title': 'Weapons', 'Link': 'https://www.rottentomatoes.com/m/weapons', 'Critics Score': '93%', 'Audience Score': '85%', 'Release Date': 'Streaming Sep 9, 2025'}, {'Title': 'Klaus', 'Link': 'https://www.rottentomatoes.com/m/klaus', 'Critics Score': '95%', 'Audience Score': '96%', 'Release Date': 'Streaming Nov 15, 2019'}, {'Title': 'Knives Out', 'Link': 'https://www.rottentomatoes.com/m/knives_out', 'Critics Score': '97%', 'Audience Score': '92%', 'Release Date': 'Streaming Jun 12, 2020'}, {'Title': \"If I Had Legs I'd Kick You\", 'Link': 'https://www.rottentomatoes.com/m/if_i_had_legs_id_kick_you', 'Critics Score': '92%', 'Audience Score': '79%', 'Release Date': 'Streaming Nov 18, 2025'}, {'Title': 'A HOUSE OF DYNAMITE', 'Link': 'https://www.rottentomatoes.com/m/a_house_of_dynamite', 'Critics Score': '75%', 'Audience Score': '77%', 'Release Date': 'Streaming Oct 24, 2025'}, {'Title': 'Die Hard', 'Link': 'https://www.rottentomatoes.com/m/die_hard', 'Critics Score': '94%', 'Audience Score': '94%', 'Release Date': 'Streaming Sep 2, 2014'}, {'Title': 'Caught Stealing', 'Link': 'https://www.rottentomatoes.com/m/caught_stealing', 'Critics Score': '84%', 'Audience Score': '83%', 'Release Date': 'Streaming Sep 30, 2025'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame (all_movies)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gaRdJcEOV5H1",
        "outputId": "acf3a0dd-5a67-4f62-8fb0-7cd3f65c4489"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Title  \\\n",
              "0                                Happyend   \n",
              "1                One Battle After Another   \n",
              "2  Wake Up Dead Man: A Knives Out Mystery   \n",
              "3                            Train Dreams   \n",
              "4                                Eternity   \n",
              "\n",
              "                                                Link Critics Score  \\\n",
              "0          https://www.rottentomatoes.com/m/happyend           98%   \n",
              "1  https://www.rottentomatoes.com/m/one_battle_af...           95%   \n",
              "2  https://www.rottentomatoes.com/m/wake_up_dead_...           92%   \n",
              "3      https://www.rottentomatoes.com/m/train_dreams           95%   \n",
              "4     https://www.rottentomatoes.com/m/eternity_2025           78%   \n",
              "\n",
              "  Audience Score            Release Date  \n",
              "0            N/A   Streaming Jan 2, 2026  \n",
              "1            85%  Streaming Nov 14, 2025  \n",
              "2            94%  Streaming Dec 12, 2025  \n",
              "3            90%  Streaming Nov 21, 2025  \n",
              "4            91%  Streaming Dec 23, 2025  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66521209-7928-41ae-a6b6-9b269f7396af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Link</th>\n",
              "      <th>Critics Score</th>\n",
              "      <th>Audience Score</th>\n",
              "      <th>Release Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Happyend</td>\n",
              "      <td>https://www.rottentomatoes.com/m/happyend</td>\n",
              "      <td>98%</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Streaming Jan 2, 2026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One Battle After Another</td>\n",
              "      <td>https://www.rottentomatoes.com/m/one_battle_af...</td>\n",
              "      <td>95%</td>\n",
              "      <td>85%</td>\n",
              "      <td>Streaming Nov 14, 2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wake Up Dead Man: A Knives Out Mystery</td>\n",
              "      <td>https://www.rottentomatoes.com/m/wake_up_dead_...</td>\n",
              "      <td>92%</td>\n",
              "      <td>94%</td>\n",
              "      <td>Streaming Dec 12, 2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train Dreams</td>\n",
              "      <td>https://www.rottentomatoes.com/m/train_dreams</td>\n",
              "      <td>95%</td>\n",
              "      <td>90%</td>\n",
              "      <td>Streaming Nov 21, 2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eternity</td>\n",
              "      <td>https://www.rottentomatoes.com/m/eternity_2025</td>\n",
              "      <td>78%</td>\n",
              "      <td>91%</td>\n",
              "      <td>Streaming Dec 23, 2025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66521209-7928-41ae-a6b6-9b269f7396af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66521209-7928-41ae-a6b6-9b269f7396af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66521209-7928-41ae-a6b6-9b269f7396af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4 : Scrape and Categorize News Articles from a JavaScript-Enabled News Site\n",
        "Task:<br>\n",
        "- Visit this website.\n",
        "- Scrape news article titles and their publication dates.\n",
        "- Categorize articles based on their publication month.\n",
        "\n",
        "Instructions:<br>\n",
        "- Use Selenium to navigate to a specific news section on the website.\n",
        "- Extract and parse the HTML content that is dynamically loaded via JavaScript.\n",
        "- Using BeautifulSoup, extract news article titles and publication dates.\n",
        "- Categorize articles by their publication month (e.g., ‘January’, ‘February’, etc.).\n",
        "- Print the categorized lists of articles."
      ],
      "metadata": {
        "id": "JIt05402aSGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "driver.get(\"https://www.bbc.com/innovation/technology\")\n",
        "time.sleep(5)\n",
        "\n",
        "soup_main = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "links = soup_main.find_all('a', href=lambda x: x and '/articles/' in x)\n",
        "urls = list(set(['https://www.bbc.com' + l['href'] for l in links if l['href'].startswith('/')]))\n",
        "\n",
        "print(f\"links: {len(urls)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjDYN7C9ajzT",
        "outputId": "89eae2a2-5e25-40e2-eae1-8735727fb5b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "links: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_articles = []\n",
        "\n",
        "for url in urls[:15]:\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "\n",
        "    title_el = soup.find('h1', class_='idLnWK')\n",
        "    date_el = soup.find('time', class_='diehpQ')\n",
        "\n",
        "    if title_el and date_el:\n",
        "        all_articles.append({\n",
        "            'Title': title_el.get_text(strip=True),\n",
        "            'Date': date_el.get('datetime')\n",
        "            })\n",
        "\n",
        "print(all_articles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-6zEPpSshaB",
        "outputId": "1a1da5de-3268-4589-e08c-2f2e657dcbdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Title': 'Waymo robotaxis stop in the streets during San Francisco power outage', 'Date': '2025-12-22T17:04:47.221Z'}, {'Title': 'Many new UK drone users must take theory test before flying outside', 'Date': '2025-12-29T00:02:30.246Z'}, {'Title': 'Both of these influencers are successful - but only one is human', 'Date': '2025-12-27T00:41:28.711Z'}, {'Title': 'Rainbow Six servers back online after apparent hack', 'Date': '2025-12-29T11:29:48.506Z'}, {'Title': \"Ghosts house 'protected' by digital mapping\", 'Date': '2025-12-28T07:14:11.580Z'}, {'Title': 'Uber and Lyft announce plans to trial Chinese robotaxis in UK in 2026', 'Date': '2025-12-22T14:08:48.454Z'}, {'Title': \"UK to ban deepfake AI 'nudification' apps\", 'Date': '2025-12-18T17:43:14.785Z'}, {'Title': \"'LeBron James of spreadsheets' wins world Microsoft Excel title\", 'Date': '2025-12-20T03:11:56.091Z'}, {'Title': \"India's first gene-edited sheep just turned one. How's it doing?\", 'Date': '2025-12-27T01:41:35.985Z'}, {'Title': 'Are these AI prompts damaging your thinking skills?', 'Date': '2025-12-20T01:45:06.877Z'}, {'Title': 'AI likely to displace jobs, says Bank of England governor', 'Date': '2025-12-19T06:00:08.983Z'}, {'Title': 'The showers and baths keeping data centre tech cool', 'Date': '2025-12-23T00:04:45.607Z'}, {'Title': 'TikTok removes AI weight loss ads from fake Boots account', 'Date': '2025-12-23T09:23:51.935Z'}, {'Title': 'Will the US TikTok deal make it safer but less relevant?', 'Date': '2025-12-19T13:45:50.063Z'}, {'Title': 'James Bond game 007 First Light delayed to May 2026', 'Date': '2025-12-29T10:22:44.967Z'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import datetime\n",
        "categorized = defaultdict(list)\n",
        "\n",
        "for item in all_articles:\n",
        "    try:\n",
        "        raw_date = item['Date'].split('T')[0]\n",
        "        date_obj = datetime.datetime.strptime(raw_date, '%Y-%m-%d')\n",
        "        month_name = date_obj.strftime('%B')\n",
        "\n",
        "        categorized[month_name].append(item['Title'])\n",
        "    except Exception as e:\n",
        "        continue"
      ],
      "metadata": {
        "id": "ZAdEOJvptfdL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Result by month:\")\n",
        "for month, titles in categorized.items():\n",
        "    print(f\"\\n--- {month} ---\")\n",
        "    for t in titles:\n",
        "        print(f\" • {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgctW7RhuAGD",
        "outputId": "16b4dbe7-57f3-4ecd-b98a-9953570ce0af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result by month:\n",
            "\n",
            "--- December ---\n",
            " • Waymo robotaxis stop in the streets during San Francisco power outage\n",
            " • Many new UK drone users must take theory test before flying outside\n",
            " • Both of these influencers are successful - but only one is human\n",
            " • Rainbow Six servers back online after apparent hack\n",
            " • Ghosts house 'protected' by digital mapping\n",
            " • Uber and Lyft announce plans to trial Chinese robotaxis in UK in 2026\n",
            " • UK to ban deepfake AI 'nudification' apps\n",
            " • 'LeBron James of spreadsheets' wins world Microsoft Excel title\n",
            " • India's first gene-edited sheep just turned one. How's it doing?\n",
            " • Are these AI prompts damaging your thinking skills?\n",
            " • AI likely to displace jobs, says Bank of England governor\n",
            " • The showers and baths keeping data centre tech cool\n",
            " • TikTok removes AI weight loss ads from fake Boots account\n",
            " • Will the US TikTok deal make it safer but less relevant?\n",
            " • James Bond game 007 First Light delayed to May 2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5 : Scrape and Analyze Weather Data from a JavaScript-Enabled Weather Website\n",
        "Task:<br>\n",
        "- Visit this website.\n",
        "- Scrape weather forecast data including temperature, condition, and humidity.\n",
        "- Analyze the data to find the average temperature and most common weather condition.\n",
        "\n",
        "Instructions:\n",
        "- Use Selenium to navigate to the weather forecast page of a specific city.\n",
        "- Extract and parse the HTML content, focusing on dynamically loaded weather data.\n",
        "- Using BeautifulSoup, extract relevant weather information like temperature, condition (sunny, cloudy, etc.), and humidity.\n",
        "- Calculate the average temperature and identify the most common weather condition.\n",
        "- Print the analysis results."
      ],
      "metadata": {
        "id": "wlKEdrY41bix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "url = 'https://www.accuweather.com/en/il/bat-yam/212477/daily-weather-forecast/212477'\n",
        "driver.get(url)\n",
        "time.sleep(5)\n",
        "\n",
        "html_content = driver.page_source\n",
        "\n",
        "print(html_content[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wospYq51v-y",
        "outputId": "917fda5b-7741-4f91-a266-7423a1d266ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html dir=\"ltr\" lang=\"en\"><head>\n",
            "  <meta charset=\"utf-8\">\n",
            "  <meta name=\"color-scheme\" content=\"light dark\">\n",
            "  <meta name=\"theme-color\" content=\"#fff\">\n",
            "  <meta name=\"viewport\" content=\"width=device-wid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "# html immitation\n",
        "mock_html = \"\"\"\n",
        "<div class=\"daily-wrapper\">\n",
        "    <a class=\"daily-forecast-card\">\n",
        "        <div class=\"info\">\n",
        "            <div class=\"temp\">\n",
        "                <span class=\"high\">18°</span>\n",
        "                <span class=\"low\">/14°</span>\n",
        "            </div>\n",
        "            <div class=\"phrase\">Partly sunny</div>\n",
        "        </div>\n",
        "        <div class=\"precip\"> 58% </div>\n",
        "    </a>\n",
        "    <a class=\"daily-forecast-card\">\n",
        "        <div class=\"info\">\n",
        "            <div class=\"temp\">\n",
        "                <span class=\"high\">20°</span>\n",
        "                <span class=\"low\">/15°</span>\n",
        "            </div>\n",
        "            <div class=\"phrase\">Cloudy</div>\n",
        "        </div>\n",
        "        <div class=\"precip\"> 10% </div>\n",
        "    </a>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(mock_html, 'html.parser')\n",
        "\n",
        "weather_cards = soup.find_all('a', class_='daily-forecast-card')\n",
        "all_conditions = []\n",
        "\n",
        "for card in weather_cards:\n",
        "    high_el = card.find('span', class_='high')\n",
        "    low_el = card.find('span', class_='low')\n",
        "    condition_el = card.find('div', class_='phrase')\n",
        "    precip_el = card.find('div', class_='precip')\n",
        "\n",
        "    if high_el:\n",
        "        h_temp = int(high_el.get_text(strip=True).replace('°', ''))\n",
        "        l_temp = low_el.get_text(strip=True).replace('°', '').replace('/', '')\n",
        "\n",
        "        all_conditions.append({\n",
        "            'High': h_temp,\n",
        "            'Low': l_temp,\n",
        "            'Condition': condition_el.get_text(strip=True) if condition_el else 'N/A',\n",
        "            'Precip': precip_el.get_text(strip=True) if precip_el else '0%'\n",
        "        })\n",
        "\n",
        "\n",
        "if all_conditions:\n",
        "    temps = [day['High'] for day in all_conditions]\n",
        "    avg_temp = sum(temps) / len(temps)\n",
        "\n",
        "\n",
        "    conds = [day['Condition'] for day in all_conditions]\n",
        "    most_common = Counter(conds).most_common(1)[0][0]\n",
        "\n",
        "\n",
        "    print(\"--- WEATHER FORECAST ANALYSIS ---\")\n",
        "    print(f\"Average max temperature: {avg_temp:.1f}°C\")\n",
        "    print(f\"Most common condition: {most_common}\")\n",
        "    print(\"-\" * 30)\n",
        "    for day in all_conditions:\n",
        "        print(f\"Max: {day['High']}°C | Precipitation: {day['Precip']} | {day['Condition']}\")\n",
        "else:\n",
        "    print(\"Data not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pOtcg3NGQ9A",
        "outputId": "e5509d86-eee5-46a3-958c-23e4b422ffa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- АНАЛИЗ ПРОГНОЗА ПОГОДЫ ---\n",
            "Средняя макс. температура: 19.0°C\n",
            "Самое частое состояние: Partly sunny\n",
            "------------------------------\n",
            "Макс: 18°C | Осадки: 58% | Partly sunny\n",
            "Макс: 20°C | Осадки: 10% | Cloudy\n"
          ]
        }
      ]
    }
  ]
}