{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Calculating Required Sample Size\n",
        "You are planning an A/B test to evaluate the impact of a new email subject line on the open rate. Based on past data, you expect a small effect size of 0.3 (an increase from 20% to 23% in the open rate). You aim for an 80% chance (power = 0.8) of detecting this effect if it exists, with a 5% significance level (α = 0.05).\n",
        "\n",
        "Calculate the required sample size per group using Python’s statsmodels library.\n",
        "What sample size is needed for each group to ensure your test is properly powered?"
      ],
      "metadata": {
        "id": "Wp6DVFE9lL1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfon66cYlIJM",
        "outputId": "7ff0d842-0723-4370-b447-b5705475905a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size per group: 175.38\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# Define the parameters\n",
        "effect_size = 0.3\n",
        "alpha = 0.05\n",
        "power = 0.8\n",
        "\n",
        "# Calculate the sample size\n",
        "analysis = TTestIndPower()\n",
        "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "print(f'Required sample size per group: {sample_size:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Understanding the Relationship Between Effect Size and Sample Size\n",
        "Using the same A/B test setup as in Exercise 1, you want to explore how changing the expected effect size impacts the required sample size.\n",
        "\n",
        "Calculate the required sample size for the following effect sizes: 0.2, 0.4, and 0.5, keeping the significance level and power the same.\n",
        "How does the sample size change as the effect size increases? Explain why this happens."
      ],
      "metadata": {
        "id": "XPF35REkmW0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effect_size = 0.2\n",
        "sample_size_2 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "effect_size = 0.4\n",
        "sample_size_3 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "effect_size = 0.5\n",
        "sample_size_4 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "\n",
        "\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (effect size is 0.2): {sample_size_2:.2f}')\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (effect size is 0.4): {sample_size_3:.2f}')\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (effect size is 0.5): {sample_size_4:.2f}')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OirRbMPXl2_P",
        "outputId": "32c6b98b-3166-446e-9abc-ec1bc0df2de0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Required sample size per group (effect size is 0.2): 393.41\n",
            "======================================================================\n",
            "Required sample size per group (effect size is 0.4): 99.08\n",
            "======================================================================\n",
            "Required sample size per group (effect size is 0.5): 63.77\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the expected effect size is small, a larger sample size is required to provide enough statistical power to detect that change."
      ],
      "metadata": {
        "id": "cU5pMxyJoGpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Exploring the Impact of Statistical Power\n",
        "Imagine you are conducting an A/B test where you expect a small effect size of 0.2. You initially plan for a power of 0.8 but wonder how increasing or decreasing the desired power level impacts the required sample size.\n",
        "\n",
        "Calculate the required sample size for power levels of 0.7, 0.8, and 0.9, keeping the effect size at 0.2 and significance level at 0.05.\n",
        "Question: How does the required sample size change with different levels of statistical power? Why is this understanding important when designing A/B tests?"
      ],
      "metadata": {
        "id": "VZTzB4Hco-oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters\n",
        "effect_size = 0.2\n",
        "alpha = 0.05\n",
        "power = 0.7\n",
        "\n",
        "# Calculate the sample size\n",
        "analysis = TTestIndPower()\n",
        "sample_size_5 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "\n",
        "power = 0.8\n",
        "sample_size_6 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "\n",
        "power = 0.9\n",
        "sample_size_7 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (power is 0.7): {sample_size_5:.2f}')\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (power is 0.8): {sample_size_6:.2f}')\n",
        "print('=' * 70)\n",
        "print(f'Required sample size per group (power is 0.9): {sample_size_7:.2f}')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjsAYkI3o4xq",
        "outputId": "0d569671-a744-4b65-a5f9-a75c5b8d949e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Required sample size per group (power is 0.7): 309.56\n",
            "======================================================================\n",
            "Required sample size per group (power is 0.8): 393.41\n",
            "======================================================================\n",
            "Required sample size per group (power is 0.9): 526.33\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher statistical power increases our chances of detecting a real effect. However, to achieve this higher power, we must increase the sample size."
      ],
      "metadata": {
        "id": "hq9MPw9q4Anx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Implementing Sequential Testing\n",
        "You are running an A/B test on two versions of a product page to increase the purchase rate. You plan to monitor the results weekly and stop the test early if one version shows a significant improvement.\n",
        "\n",
        "Define your stopping criteria.\n",
        "Decide how you would implement sequential testing in this scenario.\n",
        "At the end of week three, Version B has a p-value of 0.02. What would you do next?\n",
        "\n",
        "- Stopping Criteria: I will use adjusted significance boundaries based on an Alpha Spending Function. The test will stop if the p-value at a weekly check is lower than the predefined alpha-threshold for that specific time point.\n",
        "- Implementation: I will apply the O’Brien-Fleming approach. This allows for early stopping for efficacy while controlling the overall Type I error rate at $5\\%$.\n",
        "- Action at Week 3: Given that the p-value is $0.02$ at the third interim analysis, this would likely cross the O’Brien-Fleming boundary. I would stop the test early and implement Version B, as we have gathered sufficient evidence of its superiority without compromising the statistical integrity of the experiment."
      ],
      "metadata": {
        "id": "vUGIuBti5KQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5: Applying Bayesian A/B Testing\n",
        "You’re testing a new feature in your app, and you want to use a Bayesian approach. Initially, you believe the new feature has a 50% chance of improving user engagement. After collecting data, your analysis suggests a 65% probability that the new feature is better.\n",
        "\n",
        "Describe how you would set up your prior belief.\n",
        "After collecting data, how does the updated belief (posterior distribution) influence your decision?\n",
        "What would you do if the posterior probability was only 55%?\n",
        "\n",
        "\n",
        "- Do not implement yet: The error probability (35–45%) is far too high to justify a sound business decision.\n",
        "\n",
        "- Continue data collection: We need to gather more data to \"narrow\" the distribution, allowing the posterior probability to shift closer to a 95% confidence threshold.\n",
        "\n",
        "- Check Expected Loss: In Bayesian testing, we don't just look at the probability of winning; we also evaluate the \"Expected Loss\"—how much we stand to lose if Version B is actually worse. If the potential downside is significant, we should aim for 99% certainty."
      ],
      "metadata": {
        "id": "zH-j0mbO8E5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6: Implementing Adaptive Experimentation\n",
        "You’re running a test with three different website layouts to increase user engagement. Initially, each layout gets 33% of the traffic. After the first week, Layout C shows higher engagement.\n",
        "\n",
        "- Explain how you would adjust the traffic allocation after the first week.\n",
        "- Describe how you would continue to adapt the experiment in the following weeks.\n",
        "- What challenges might you face with adaptive experimentation, and how would you address them?\n",
        "\n",
        "\n",
        "1. Traffic Adjustment: I would use an algorithm like Thompson Sampling to shift more traffic toward Layout C. Instead of 33%, Layout C might receive 70-80% of the traffic based on its probability of being the optimal choice.\n",
        "\n",
        "2. Continuous Adaptation: I would maintain a balance between Exploration and Exploitation. The system will continuously monitor data; if Layout C remains the leader, its share stays high. If Layout B starts performing better, the algorithm will dynamically shift traffic back to B.\n",
        "\n",
        "3. Challenges: A major challenge is the Novelty Effect, where a layout performs well initially just because it's new. I would address this by keeping a \"holdout\" or ensuring a minimum traffic floor for all versions to observe long-term stability."
      ],
      "metadata": {
        "id": "UIoaCZ1gU0nx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IDtwmOAQWDNP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}